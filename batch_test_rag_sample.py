#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æµ‹è¯•RAGç®¡é“è„šæœ¬ - Task 5 (æ ·ä¾‹æµ‹è¯•ç‰ˆ)
ç«¯åˆ°ç«¯é›†æˆä¸æ‰¹é‡æµ‹è¯•ï¼Œä»…å¤„ç†å‰20ä¸ªæ ·ä¾‹éªŒè¯æµç¨‹
"""

import json
import os
import time
from datetime import datetime
from dotenv import load_dotenv
from tqdm import tqdm
from rag_pipeline import RAGPipeline
import numpy as np

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def load_test_data(file_path, limit=20):
    """åŠ è½½æµ‹è¯•æ•°æ®ï¼Œé™åˆ¶æ•°é‡"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data[:limit]  # åªå–å‰limitä¸ªæ ·ä¾‹

def json_serializer(obj):
    """JSONåºåˆ—åŒ–è½¬æ¢å‡½æ•°ï¼Œå¤„ç†numpyæ•°æ®ç±»å‹"""
    if isinstance(obj, (np.integer, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    raise TypeError(f'Object of type {obj.__class__.__name__} is not JSON serializable')

def save_results(results, output_file):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=json_serializer)

def main():
    print("=" * 60)
    print("Task 5: ç«¯åˆ°ç«¯é›†æˆä¸æ‰¹é‡æµ‹è¯• (æ ·ä¾‹æµ‹è¯• - å‰20ä¸ª)")
    print("=" * 60)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    test_file = "test.json"  # ä½¿ç”¨test.jsonä½œä¸ºæµ‹è¯•æ•°æ®é›†
    if not os.path.exists(test_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶ {test_file}")
        return
    
    # ç¡®ä¿outputç›®å½•å­˜åœ¨
    os.makedirs("output", exist_ok=True)
    
    # åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆä»…å‰20ä¸ªï¼‰
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®: {test_file} (ä»…å‰20ä¸ªæ ·ä¾‹)")
    test_data = load_test_data(test_file, limit=20)
    print(f"âœ“ åŠ è½½å®Œæˆï¼Œå…± {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # åˆå§‹åŒ–æ€§èƒ½æ—¥å¿—
    log_entries = []
    start_time = datetime.now()
    log_entries.append(f"æ ·ä¾‹æµ‹è¯•å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    log_entries.append(f"æµ‹è¯•æ•°æ®é›†: {test_file}")
    log_entries.append(f"æ ·ä¾‹æ•°é‡: {len(test_data)} (å‰20ä¸ª)")
    
    # åˆå§‹åŒ–RAGç®¡é“
    print("\næ­£åœ¨åˆå§‹åŒ–RAGç®¡é“...")
    try:
        rag = RAGPipeline(
            index_path="output/knowledge_base.index",
            metadata_path="output/chunk_metadata.pkl",
            k=5
        )
        print("âœ“ RAGç®¡é“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— RAGç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æ‰¹é‡æµ‹è¯•
    print(f"\nå¼€å§‹æ‰¹é‡æµ‹è¯• {len(test_data)} ä¸ªé—®é¢˜...")
    results = []  # è¯¦ç»†æµ‹è¯•ç»“æœ
    submission_results = []  # submission.jsonæ ¼å¼ç»“æœ
    
    successful_count = 0
    failed_count = 0
    total_processing_time = 0
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
    for i, item in enumerate(tqdm(test_data, desc="å¤„ç†é—®é¢˜"), 1):
        question_start_time = time.time()
        
        try:
            # ä½¿ç”¨RAGç®¡é“å›ç­”é—®é¢˜
            result = rag.answer_question(item['question'])
            question_end_time = time.time()
            processing_time = question_end_time - question_start_time
            total_processing_time += processing_time
            
            # è®°å½•è¯¦ç»†ç»“æœ
            test_result = {
                "id": i,
                "filename": item['filename'],
                "page": item['page'],
                "question": item['question'],
                "expected_answer": item['answer'],
                "rag_answer": result['answer'],
                "sources": result['sources'],
                "processing_time": processing_time,
                "success": True
            }
            
            # è®°å½•submissionæ ¼å¼ç»“æœ
            submission_result = {
                "answer": result['answer'],
                "filename": item['filename'],
                "page": item['page']
            }
            
            successful_count += 1
            log_entries.append(f"é—®é¢˜ {i}: æˆåŠŸ (è€—æ—¶: {processing_time:.2f}s)")
            
        except Exception as e:
            question_end_time = time.time()
            processing_time = question_end_time - question_start_time
            total_processing_time += processing_time
            
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            
            # è®°å½•è¯¦ç»†ç»“æœ
            test_result = {
                "id": i,
                "filename": item['filename'],
                "page": item['page'],
                "question": item['question'],
                "expected_answer": item['answer'],
                "rag_answer": error_msg,
                "sources": [],
                "processing_time": processing_time,
                "success": False
            }
            
            # è®°å½•submissionæ ¼å¼ç»“æœï¼ˆå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰
            submission_result = {
                "answer": "æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚",
                "filename": item['filename'],
                "page": item['page']
            }
            
            failed_count += 1
            log_entries.append(f"é—®é¢˜ {i}: å¤±è´¥ - {str(e)} (è€—æ—¶: {processing_time:.2f}s)")
        
        results.append(test_result)
        submission_results.append(submission_result)
    
    # è®¡ç®—æ€»ä½“æ€§èƒ½æŒ‡æ ‡
    end_time = datetime.now()
    total_duration = (end_time - start_time).total_seconds()
    avg_processing_time = total_processing_time / len(test_data) if test_data else 0
    success_rate = (successful_count / len(test_data) * 100) if test_data else 0
    
    # æ·»åŠ æ€§èƒ½ç»Ÿè®¡åˆ°æ—¥å¿—
    log_entries.extend([
        f"æ ·ä¾‹æµ‹è¯•ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"æ€»è€—æ—¶: {total_duration:.2f}ç§’",
        f"æˆåŠŸå›ç­”æ•°: {successful_count}",
        f"å¤±è´¥æ•°: {failed_count}",
        f"æˆåŠŸç‡: {success_rate:.1f}%",
        f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}ç§’/é—®é¢˜",
        f"æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f}ç§’"
    ])
    
    # ä¿å­˜submission.jsonæ–‡ä»¶ï¼ˆæ ·ä¾‹ç‰ˆï¼‰
    submission_file = "output/submission_sample.json"
    print(f"\næ­£åœ¨ä¿å­˜æ ·ä¾‹æäº¤æ–‡ä»¶: {submission_file}")
    with open(submission_file, 'w', encoding='utf-8') as f:
        json.dump(submission_results, f, ensure_ascii=False, indent=2, default=json_serializer)
    print(f"âœ“ æ ·ä¾‹æäº¤æ–‡ä»¶ä¿å­˜å®Œæˆ")
    
    # ä¿å­˜è¯¦ç»†æµ‹è¯•ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    detailed_results_file = f"output/rag_test_results_sample_{timestamp}.json"
    print(f"\næ­£åœ¨ä¿å­˜è¯¦ç»†æµ‹è¯•ç»“æœ: {detailed_results_file}")
    save_results(results, detailed_results_file)
    print(f"âœ“ è¯¦ç»†ç»“æœä¿å­˜å®Œæˆ")
    
    # ä¿å­˜æ€§èƒ½æ—¥å¿—
    log_file = "output/sample_performance_log.txt"
    print(f"\næ­£åœ¨ä¿å­˜æ€§èƒ½æ—¥å¿—: {log_file}")
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(log_entries))
    print(f"âœ“ æ€§èƒ½æ—¥å¿—ä¿å­˜å®Œæˆ")
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 60)
    print("Task 5 æ ·ä¾‹æµ‹è¯•å®Œæˆç»Ÿè®¡")
    print("=" * 60)
    print(f"æ ·ä¾‹æµ‹è¯•æ•°é‡: {len(results)}")
    print(f"æˆåŠŸæ•°é‡: {successful_count}")
    print(f"å¤±è´¥æ•°é‡: {failed_count}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
    print(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}ç§’/é—®é¢˜")
    print(f"\nç”Ÿæˆæ–‡ä»¶:")
    print(f"  - æ ·ä¾‹æäº¤æ–‡ä»¶: {submission_file}")
    print(f"  - è¯¦ç»†ç»“æœ: {detailed_results_file}")
    print(f"  - æ€§èƒ½æ—¥å¿—: {log_file}")
    print("=" * 60)
    
    # éªŒè¯æµç¨‹å®Œæ•´æ€§
    print("\n" + "=" * 60)
    print("æµç¨‹å®Œæ•´æ€§éªŒè¯")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
    files_to_check = [submission_file, detailed_results_file, log_file]
    all_files_exist = True
    
    for file_path in files_to_check:
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            print(f"âœ“ {file_path} - æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        else:
            print(f"âœ— {file_path} - æ–‡ä»¶ä¸å­˜åœ¨")
            all_files_exist = False
    
    if all_files_exist and successful_count > 0:
        print(f"\nğŸ‰ æ ·ä¾‹æµ‹è¯•æµç¨‹éªŒè¯æˆåŠŸï¼")
        print(f"   - æˆåŠŸå¤„ç†äº† {successful_count}/{len(test_data)} ä¸ªé—®é¢˜")
        print(f"   - æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å‡å·²æ­£ç¡®ç”Ÿæˆ")
        print(f"   - å¯ä»¥ç»§ç»­è¿›è¡Œå®Œæ•´æµ‹è¯•")
    else:
        print(f"\nâš ï¸  æ ·ä¾‹æµ‹è¯•å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥åå†è¿›è¡Œå®Œæ•´æµ‹è¯•")
    
    print("=" * 60)

if __name__ == "__main__":
    main()