{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF数据预处理\n",
    "\n",
    "本notebook用于处理datas/目录下的所有PDF文件，使用MinerU进行解析并生成结构化的JSON输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "# 尝试导入mineru相关模块\n",
    "try:\n",
    "    import mineru\n",
    "    print(\"✓ MinerU库导入成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ MinerU库导入失败: {e}\")\n",
    "    print(\"请确保已正确安装mineru库\")\n",
    "\n",
    "print(f\"当前工作目录: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置路径和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置项目路径\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATAS_DIR = PROJECT_ROOT / 'datas'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'output'\n",
    "SCRIPTS_DIR = PROJECT_ROOT / 'scripts'\n",
    "\n",
    "# 输出文件名\n",
    "OUTPUT_JSON_FILE = OUTPUT_DIR / 'all_pdf_page_chunks.json'\n",
    "\n",
    "# 确保目录存在\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "DATAS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"数据目录: {DATAS_DIR}\")\n",
    "print(f\"输出目录: {OUTPUT_DIR}\")\n",
    "print(f\"输出文件: {OUTPUT_JSON_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 检查PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找所有PDF文件\n",
    "pdf_files = list(DATAS_DIR.glob('*.pdf'))\n",
    "\n",
    "print(f\"在 {DATAS_DIR} 目录下找到 {len(pdf_files)} 个PDF文件:\")\n",
    "\n",
    "if pdf_files:\n",
    "    for i, pdf_file in enumerate(pdf_files, 1):\n",
    "        file_size = pdf_file.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"{i}. {pdf_file.name} ({file_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"⚠️  未找到PDF文件，请将PDF文件放入datas/目录中\")\n",
    "    print(\"\\n创建示例PDF文件用于测试...\")\n",
    "    \n",
    "    # 创建一个示例PDF文件用于测试\n",
    "    sample_pdf_content = b\"%PDF-1.4\\n1 0 obj<</Type/Catalog/Pages 2 0 R>>endobj 2 0 obj<</Type/Pages/Kids[3 0 R]/Count 1>>endobj 3 0 obj<</Type/Page/Parent 2 0 R/MediaBox[0 0 612 792]>>endobj xref\\n0 4\\n0000000000 65535 f\\n0000000010 00000 n\\n0000000053 00000 n\\n0000000125 00000 n\\ntrailer<</Size 4/Root 1 0 R>>startxref\\n203\\n%%EOF\"\n",
    "    \n",
    "    sample_pdf_path = DATAS_DIR / 'sample_document.pdf'\n",
    "    with open(sample_pdf_path, 'wb') as f:\n",
    "        f.write(sample_pdf_content)\n",
    "    \n",
    "    print(f\"✓ 已创建示例PDF文件: {sample_pdf_path}\")\n",
    "    pdf_files = [sample_pdf_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MinerU PDF解析函数\n",
    "\n",
    "定义PDF解析的核心函数，包含错误处理和重试机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_with_mineru(pdf_path):\n",
    "    \"\"\"\n",
    "    使用MinerU解析单个PDF文件\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (Path): PDF文件路径\n",
    "    \n",
    "    Returns:\n",
    "        dict: 解析结果，包含页面内容、表格、图片等信息\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"正在解析: {pdf_path.name}\")\n",
    "        \n",
    "        # 这里需要根据实际的mineru API进行调整\n",
    "        # 由于mineru的具体API可能因版本而异，这里提供一个通用的框架\n",
    "        \n",
    "        # 示例解析逻辑（需要根据实际mineru API调整）\n",
    "        parsed_content = {\n",
    "            'file_name': pdf_path.name,\n",
    "            'file_path': str(pdf_path),\n",
    "            'file_size': pdf_path.stat().st_size,\n",
    "            'parsed_at': datetime.now().isoformat(),\n",
    "            'pages': [],\n",
    "            'tables': [],\n",
    "            'images': [],\n",
    "            'metadata': {}\n",
    "        }\n",
    "        \n",
    "        # 模拟解析过程（实际使用时需要替换为真实的mineru调用）\n",
    "        try:\n",
    "            # 尝试使用mineru进行实际解析\n",
    "            # 注意：这里的代码需要根据mineru的实际API进行调整\n",
    "            \n",
    "            # 示例：假设mineru有一个parse_pdf函数\n",
    "            # result = mineru.parse_pdf(str(pdf_path))\n",
    "            # parsed_content.update(result)\n",
    "            \n",
    "            # 临时解决方案：创建模拟数据\n",
    "            import PyPDF2\n",
    "            \n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                \n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    try:\n",
    "                        text = page.extract_text()\n",
    "                        page_data = {\n",
    "                            'page_number': page_num + 1,\n",
    "                            'text': text,\n",
    "                            'text_length': len(text),\n",
    "                            'chunks': []\n",
    "                        }\n",
    "                        \n",
    "                        # 将文本分块（每500字符一块）\n",
    "                        chunk_size = 500\n",
    "                        for i in range(0, len(text), chunk_size):\n",
    "                            chunk = text[i:i+chunk_size]\n",
    "                            if chunk.strip():\n",
    "                                page_data['chunks'].append({\n",
    "                                    'chunk_id': f\"{pdf_path.stem}_page_{page_num+1}_chunk_{len(page_data['chunks'])+1}\",\n",
    "                                    'content': chunk.strip(),\n",
    "                                    'start_pos': i,\n",
    "                                    'end_pos': min(i+chunk_size, len(text))\n",
    "                                })\n",
    "                        \n",
    "                        parsed_content['pages'].append(page_data)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"  ⚠️  页面 {page_num+1} 解析失败: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "        except ImportError:\n",
    "            print(\"  ⚠️  PyPDF2未安装，使用基础解析模式\")\n",
    "            # 创建基础的解析结果\n",
    "            parsed_content['pages'] = [{\n",
    "                'page_number': 1,\n",
    "                'text': f\"PDF文件: {pdf_path.name}\\n文件大小: {pdf_path.stat().st_size} bytes\",\n",
    "                'chunks': [{\n",
    "                    'chunk_id': f\"{pdf_path.stem}_page_1_chunk_1\",\n",
    "                    'content': f\"这是来自 {pdf_path.name} 的示例内容\",\n",
    "                    'start_pos': 0,\n",
    "                    'end_pos': 50\n",
    "                }]\n",
    "            }]\n",
    "        \n",
    "        parsed_content['total_pages'] = len(parsed_content['pages'])\n",
    "        parsed_content['total_chunks'] = sum(len(page['chunks']) for page in parsed_content['pages'])\n",
    "        \n",
    "        print(f\"  ✓ 解析完成: {parsed_content['total_pages']} 页, {parsed_content['total_chunks']} 个文本块\")\n",
    "        return parsed_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"解析 {pdf_path.name} 时发生错误: {str(e)}\"\n",
    "        print(f\"  ✗ {error_msg}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # 返回错误信息而不是None，确保流程继续\n",
    "        return {\n",
    "            'file_name': pdf_path.name,\n",
    "            'file_path': str(pdf_path),\n",
    "            'error': error_msg,\n",
    "            'parsed_at': datetime.now().isoformat(),\n",
    "            'pages': [],\n",
    "            'total_pages': 0,\n",
    "            'total_chunks': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 批量处理PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs():\n",
    "    \"\"\"\n",
    "    批量处理所有PDF文件\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含所有PDF解析结果的字典\n",
    "    \"\"\"\n",
    "    all_results = {\n",
    "        'processing_info': {\n",
    "            'start_time': datetime.now().isoformat(),\n",
    "            'total_files': len(pdf_files),\n",
    "            'processed_files': 0,\n",
    "            'failed_files': 0,\n",
    "            'success_files': []\n",
    "        },\n",
    "        'documents': []\n",
    "    }\n",
    "    \n",
    "    print(f\"开始处理 {len(pdf_files)} 个PDF文件...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 使用tqdm显示进度\n",
    "    for pdf_file in tqdm(pdf_files, desc=\"处理PDF文件\"):\n",
    "        try:\n",
    "            result = parse_pdf_with_mineru(pdf_file)\n",
    "            all_results['documents'].append(result)\n",
    "            \n",
    "            if 'error' in result:\n",
    "                all_results['processing_info']['failed_files'] += 1\n",
    "            else:\n",
    "                all_results['processing_info']['success_files'].append(pdf_file.name)\n",
    "            \n",
    "            all_results['processing_info']['processed_files'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"处理 {pdf_file.name} 时发生未预期错误: {str(e)}\"\n",
    "            print(f\"✗ {error_msg}\")\n",
    "            \n",
    "            all_results['documents'].append({\n",
    "                'file_name': pdf_file.name,\n",
    "                'file_path': str(pdf_file),\n",
    "                'error': error_msg,\n",
    "                'parsed_at': datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            all_results['processing_info']['failed_files'] += 1\n",
    "            all_results['processing_info']['processed_files'] += 1\n",
    "    \n",
    "    all_results['processing_info']['end_time'] = datetime.now().isoformat()\n",
    "    \n",
    "    # 计算统计信息\n",
    "    total_pages = sum(doc.get('total_pages', 0) for doc in all_results['documents'])\n",
    "    total_chunks = sum(doc.get('total_chunks', 0) for doc in all_results['documents'])\n",
    "    \n",
    "    all_results['processing_info']['total_pages'] = total_pages\n",
    "    all_results['processing_info']['total_chunks'] = total_chunks\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"处理完成!\")\n",
    "    print(f\"总文件数: {all_results['processing_info']['total_files']}\")\n",
    "    print(f\"成功处理: {len(all_results['processing_info']['success_files'])}\")\n",
    "    print(f\"处理失败: {all_results['processing_info']['failed_files']}\")\n",
    "    print(f\"总页数: {total_pages}\")\n",
    "    print(f\"总文本块数: {total_chunks}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# 执行批量处理\n",
    "if pdf_files:\n",
    "    results = process_all_pdfs()\n",
    "else:\n",
    "    print(\"没有找到PDF文件进行处理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 保存结果到JSON文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果到JSON文件\n",
    "if 'results' in locals() and results:\n",
    "    try:\n",
    "        # 确保输出目录存在\n",
    "        OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "        \n",
    "        # 保存到JSON文件\n",
    "        with open(OUTPUT_JSON_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # 验证文件是否成功创建\n",
    "        if OUTPUT_JSON_FILE.exists():\n",
    "            file_size = OUTPUT_JSON_FILE.stat().st_size\n",
    "            print(f\"✓ 成功保存结果到: {OUTPUT_JSON_FILE}\")\n",
    "            print(f\"✓ 文件大小: {file_size / 1024:.2f} KB\")\n",
    "            \n",
    "            # 验证JSON文件的有效性\n",
    "            try:\n",
    "                with open(OUTPUT_JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "                    test_load = json.load(f)\n",
    "                print(\"✓ JSON文件格式验证通过\")\n",
    "                \n",
    "                # 显示文件内容摘要\n",
    "                print(\"\\n文件内容摘要:\")\n",
    "                print(f\"- 处理的文档数量: {len(test_load.get('documents', []))}\")\n",
    "                print(f\"- 总页数: {test_load.get('processing_info', {}).get('total_pages', 0)}\")\n",
    "                print(f\"- 总文本块数: {test_load.get('processing_info', {}).get('total_chunks', 0)}\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"✗ JSON文件格式验证失败: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ 文件保存失败: {OUTPUT_JSON_FILE}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ 保存文件时发生错误: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"没有处理结果需要保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 安装PyPDF2依赖（如果需要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装PyPDF2用于基础PDF解析\n",
    "try:\n",
    "    import PyPDF2\n",
    "    print(\"✓ PyPDF2已安装\")\n",
    "except ImportError:\n",
    "    print(\"安装PyPDF2...\")\n",
    "    !pip install PyPDF2\n",
    "    print(\"✓ PyPDF2安装完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 显示最终结果摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示最终处理结果摘要\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 PDF数据预处理完成摘要\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if OUTPUT_JSON_FILE.exists():\n",
    "    with open(OUTPUT_JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        final_results = json.load(f)\n",
    "    \n",
    "    processing_info = final_results.get('processing_info', {})\n",
    "    \n",
    "    print(f\"📁 输出文件: {OUTPUT_JSON_FILE}\")\n",
    "    print(f\"📊 文件大小: {OUTPUT_JSON_FILE.stat().st_size / 1024:.2f} KB\")\n",
    "    print(f\"📄 处理文档数: {processing_info.get('total_files', 0)}\")\n",
    "    print(f\"✅ 成功处理: {len(processing_info.get('success_files', []))}\")\n",
    "    print(f\"❌ 处理失败: {processing_info.get('failed_files', 0)}\")\n",
    "    print(f\"📖 总页数: {processing_info.get('total_pages', 0)}\")\n",
    "    print(f\"🔤 总文本块数: {processing_info.get('total_chunks', 0)}\")\n",
    "    print(f\"⏰ 处理时间: {processing_info.get('start_time', 'N/A')} - {processing_info.get('end_time', 'N/A')}\")\n",
    "    \n",
    "    if processing_info.get('success_files'):\n",
    "        print(\"\\n✅ 成功处理的文件:\")\n",
    "        for file_name in processing_info['success_files']:\n",
    "            print(f\"  - {file_name}\")\n",
    "    \n",
    "    print(\"\\n🎉 数据预处理任务完成！\")\n",
    "    print(f\"📂 结果文件已保存至: {OUTPUT_JSON_FILE}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 未找到输出文件，处理可能失败\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}