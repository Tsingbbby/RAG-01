{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: æ„å»ºä¸ç´¢å¼•å‘é‡çŸ¥è¯†åº“\n",
    "\n",
    "æœ¬Notebookæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Task 3çš„åŠŸèƒ½å°†Task 2ç”Ÿæˆçš„å‘é‡åŒ–çŸ¥è¯†å—æ„å»ºæˆå¯è¿›è¡Œé«˜æ•ˆç›¸ä¼¼åº¦æœç´¢çš„å‘é‡çŸ¥è¯†åº“ã€‚\n",
    "\n",
    "## ä¸»è¦åŠŸèƒ½\n",
    "\n",
    "1. **æ•°æ®åŠ è½½**: è¯»å–`vectorized_chunks.jsonl`æ–‡ä»¶\n",
    "2. **ç´¢å¼•æ„å»º**: ä½¿ç”¨FAISSæ„å»ºé«˜æ•ˆçš„å‘é‡ç´¢å¼•\n",
    "3. **GPUåŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPUåŠ é€Ÿç´¢å¼•æ„å»º\n",
    "4. **æ–‡ä»¶ä¿å­˜**: ç”Ÿæˆ`knowledge_base.index`å’Œ`chunk_metadata.pkl`æ–‡ä»¶\n",
    "\n",
    "## è¾“å‡ºæ–‡ä»¶\n",
    "\n",
    "- `output/knowledge_base.index`: FAISSäºŒè¿›åˆ¶ç´¢å¼•æ–‡ä»¶\n",
    "- `output/chunk_metadata.pkl`: å…ƒæ•°æ®æ˜ å°„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒæ£€æŸ¥ä¸ä¾èµ–å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# æ£€æŸ¥å¿…è¦çš„åº“\n",
    "try:\n",
    "    import faiss\n",
    "    print(f\"âœ… FAISSç‰ˆæœ¬: {faiss.__version__}\")\n",
    "    \n",
    "    # æ£€æŸ¥GPUæ”¯æŒ\n",
    "    gpu_count = faiss.get_num_gpus()\n",
    "    if gpu_count > 0:\n",
    "        print(f\"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿ\")\n",
    "    else:\n",
    "        print(\"ğŸ’» æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæ„å»ºç´¢å¼•\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âŒ è¯·å…ˆå®‰è£…faiss-gpu: pip install faiss-gpu\")\n",
    "\n",
    "# æ£€æŸ¥è¾“å…¥æ–‡ä»¶\n",
    "input_file = \"output/vectorized_chunks.jsonl\"\n",
    "if os.path.exists(input_file):\n",
    "    file_size = os.path.getsize(input_file) / (1024 * 1024)  # MB\n",
    "    print(f\"âœ… è¾“å…¥æ–‡ä»¶å­˜åœ¨: {input_file} ({file_size:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}\")\n",
    "    print(\"è¯·å…ˆè¿è¡ŒTask 2ç”Ÿæˆå‘é‡åŒ–æ•°æ®æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å¯¼å…¥æ„å»ºå™¨ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_index import VectorKnowledgeBaseBuilder\n",
    "\n",
    "# åˆ›å»ºæ„å»ºå™¨å®ä¾‹\n",
    "builder = VectorKnowledgeBaseBuilder(\n",
    "    input_file=\"output/vectorized_chunks.jsonl\",\n",
    "    output_dir=\"output\"\n",
    ")\n",
    "\n",
    "print(\"æ„å»ºå™¨å·²åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ‰§è¡Œå‘é‡çŸ¥è¯†åº“æ„å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œå®Œæ•´çš„æ„å»ºæµç¨‹\n",
    "try:\n",
    "    print(\"å¼€å§‹æ„å»ºå‘é‡çŸ¥è¯†åº“...\")\n",
    "    builder.build()\n",
    "    print(\"\\nğŸ‰ å‘é‡çŸ¥è¯†åº“æ„å»ºå®Œæˆ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ„å»ºå¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. éªŒè¯è¾“å‡ºæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éªŒè¯è¾“å‡ºæ–‡ä»¶\n",
    "index_file = \"output/knowledge_base.index\"\n",
    "metadata_file = \"output/chunk_metadata.pkl\"\n",
    "\n",
    "print(\"=== è¾“å‡ºæ–‡ä»¶éªŒè¯ ===\")\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§\n",
    "if os.path.exists(index_file):\n",
    "    size_mb = os.path.getsize(index_file) / (1024 * 1024)\n",
    "    print(f\"âœ… ç´¢å¼•æ–‡ä»¶: {index_file} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}\")\n",
    "\n",
    "if os.path.exists(metadata_file):\n",
    "    size_mb = os.path.getsize(metadata_file) / (1024 * 1024)\n",
    "    print(f\"âœ… å…ƒæ•°æ®æ–‡ä»¶: {metadata_file} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æµ‹è¯•æœç´¢åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æœç´¢åŠŸèƒ½\n",
    "try:\n",
    "    import faiss\n",
    "    import pickle\n",
    "    \n",
    "    # åŠ è½½ç´¢å¼•å’Œå…ƒæ•°æ®\n",
    "    index = faiss.read_index(\"output/knowledge_base.index\")\n",
    "    with open(\"output/chunk_metadata.pkl\", \"rb\") as f:\n",
    "        metadata_list = pickle.load(f)\n",
    "    \n",
    "    print(f\"ğŸ“Š ç´¢å¼•ä¿¡æ¯:\")\n",
    "    print(f\"   å‘é‡æ•°é‡: {index.ntotal:,}\")\n",
    "    print(f\"   å‘é‡ç»´åº¦: {index.d}\")\n",
    "    print(f\"   å…ƒæ•°æ®æ¡ç›®æ•°: {len(metadata_list):,}\")\n",
    "    \n",
    "    # æµ‹è¯•æœç´¢\n",
    "    if index.ntotal > 0:\n",
    "        query_vector = index.reconstruct(0).reshape(1, -1)\n",
    "        distances, indices = index.search(query_vector, k=3)\n",
    "        \n",
    "        print(f\"\\nğŸ” æœç´¢æµ‹è¯•ç»“æœ:\")\n",
    "        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            metadata = metadata_list[idx]\n",
    "            print(f\"  [{i+1}] è·ç¦»: {dist:.6f}, chunk_id: {metadata['chunk_id']}\")\n",
    "        \n",
    "        if distances[0][0] < 1e-6:\n",
    "            print(\"âœ… æœç´¢åŠŸèƒ½æ­£å¸¸\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æœç´¢ç»“æœå¼‚å¸¸\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "Task 3æˆåŠŸå®Œæˆäº†ä»¥ä¸‹åŠŸèƒ½:\n",
    "\n",
    "âœ… **æ•°æ®åŠ è½½**: ä»`vectorized_chunks.jsonl`åŠ è½½å‘é‡å’Œå…ƒæ•°æ®\n",
    "âœ… **ç´¢å¼•æ„å»º**: ä½¿ç”¨FAISS IndexFlatL2æ„å»ºé«˜æ•ˆå‘é‡ç´¢å¼•\n",
    "âœ… **GPUåŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPUåŠ é€Ÿæ„å»ºè¿‡ç¨‹\n",
    "âœ… **æ•°æ®å¯¹é½**: ç¡®ä¿å‘é‡ç´¢å¼•ä¸å…ƒæ•°æ®æ˜ å°„çš„ä¸¥æ ¼å¯¹åº”\n",
    "âœ… **æŒä¹…åŒ–å­˜å‚¨**: ç”Ÿæˆå¯é‡ç”¨çš„ç´¢å¼•å’Œå…ƒæ•°æ®æ–‡ä»¶\n",
    "âœ… **æœç´¢åŠŸèƒ½**: æ”¯æŒé«˜æ•ˆçš„ç›¸ä¼¼åº¦æœç´¢\n",
    "\n",
    "ç”Ÿæˆçš„å‘é‡çŸ¥è¯†åº“ç°åœ¨å¯ä»¥ç”¨äºRAGç³»ç»Ÿçš„å¿«é€Ÿæ£€ç´¢é˜¶æ®µã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}