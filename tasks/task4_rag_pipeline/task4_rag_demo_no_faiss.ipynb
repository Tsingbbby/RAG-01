{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: RAGæ£€ç´¢å¢å¼ºç”Ÿæˆç®¡é“æ¼”ç¤º (æ— faissä¾èµ–ç‰ˆæœ¬)\n",
    "\n",
    "æœ¬æ¼”ç¤ºå±•ç¤ºå¦‚ä½•ä½¿ç”¨æ— faissä¾èµ–çš„RAGç®¡é“è¿›è¡Œé—®ç­”ã€‚\n",
    "\n",
    "## åŠŸèƒ½ç‰¹ç‚¹\n",
    "- âœ… ä½¿ç”¨numpyå®ç°å‘é‡ç›¸ä¼¼åº¦è®¡ç®—\n",
    "- âœ… æ”¯æŒæ–‡æ¡£æ£€ç´¢å’Œç­”æ¡ˆç”Ÿæˆ\n",
    "- âœ… å®Œæ•´çš„æº¯æºå’Œç›¸ä¼¼åº¦è¯„åˆ†\n",
    "- âœ… æ— éœ€faissä¾èµ–ï¼Œå…¼å®¹æ€§æ›´å¥½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—\n",
    "from rag_pipeline_no_faiss import RAGPipelineNoFaiss\n",
    "from llm_api_client import GenerationAPIClient\n",
    "from embedding_module import EmbeddingAPIClient\n",
    "\n",
    "print('âœ“ ä¾èµ–å¯¼å…¥æˆåŠŸ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. æ£€æŸ¥å¿…è¦æ–‡ä»¶\n",
    "\n",
    "ç¡®è®¤å‘é‡ç´¢å¼•å’Œå…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å®šä¹‰æ–‡ä»¶è·¯å¾„\n",
    "index_file = 'output/document_vectors.npy'\n",
    "metadata_file = 'output/document_metadata.json'\n",
    "\n",
    "print('=== æ–‡ä»¶æ£€æŸ¥ ===')\n",
    "\n",
    "# æ£€æŸ¥å‘é‡ç´¢å¼•æ–‡ä»¶\n",
    "if os.path.exists(index_file):\n",
    "    file_size = os.path.getsize(index_file) / (1024 * 1024)  # MB\n",
    "    print(f'âœ… å‘é‡ç´¢å¼•æ–‡ä»¶å­˜åœ¨: {index_file}')\n",
    "    print(f'ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB')\n",
    "else:\n",
    "    print(f'âŒ å‘é‡ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}')\n",
    "\n",
    "# æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶\n",
    "if os.path.exists(metadata_file):\n",
    "    file_size = os.path.getsize(metadata_file) / 1024  # KB\n",
    "    print(f'âœ… å…ƒæ•°æ®æ–‡ä»¶å­˜åœ¨: {metadata_file}')\n",
    "    print(f'ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} KB')\n",
    "    \n",
    "    # è¯»å–å…ƒæ•°æ®ç»Ÿè®¡\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f'ğŸ“‹ æ–‡æ¡£æ•°é‡: {len(metadata)}')\n",
    "else:\n",
    "    print(f'âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metadata_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆå§‹åŒ–RAGç®¡é“\n",
    "\n",
    "åˆ›å»ºRAGç®¡é“å®ä¾‹å¹¶åŠ è½½å¿…è¦çš„èµ„æºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print('=== åˆå§‹åŒ–RAGç®¡é“ ===')\n",
    "\n",
    "try:\n",
    "    # åˆå§‹åŒ–RAGç®¡é“\n",
    "    rag_pipeline = RAGPipelineNoFaiss(index_file, metadata_file)\n",
    "    \n",
    "    # è·å–ç®¡é“ç»Ÿè®¡ä¿¡æ¯\n",
    "    stats = rag_pipeline.get_stats()\n",
    "    \n",
    "    print('\\nğŸ“Š ç®¡é“ç»Ÿè®¡ä¿¡æ¯:')\n",
    "    for key, value in stats.items():\n",
    "        print(f'  {key}: {value}')\n",
    "    \n",
    "    print('\\nğŸ‰ RAGç®¡é“åˆå§‹åŒ–æˆåŠŸï¼')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'âŒ RAGç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æµ‹è¯•é—®ç­”åŠŸèƒ½\n",
    "\n",
    "ä½¿ç”¨é¢„å®šä¹‰çš„æµ‹è¯•é—®é¢˜éªŒè¯RAGç®¡é“çš„åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å®šä¹‰æµ‹è¯•é—®é¢˜\n",
    "test_questions = [\n",
    "    'ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ',\n",
    "    'æœºå™¨å­¦ä¹ çš„ä¸»è¦æ–¹æ³•æœ‰å“ªäº›ï¼Ÿ',\n",
    "    'æ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ'\n",
    "]\n",
    "\n",
    "print('=== é—®ç­”æµ‹è¯• ===')\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f'\\n--- æµ‹è¯•é—®é¢˜ {i} ---')\n",
    "    print(f'é—®é¢˜: {question}')\n",
    "    \n",
    "    try:\n",
    "        # å¼€å§‹è®¡æ—¶\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # è°ƒç”¨RAGç®¡é“\n",
    "        result = rag_pipeline.answer_question(\n",
    "            question=question,\n",
    "            top_k=3,\n",
    "            max_context_length=2000\n",
    "        )\n",
    "        \n",
    "        # è®¡ç®—è€—æ—¶\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # æ˜¾ç¤ºç»“æœ\n",
    "        print(f'\\nğŸ“ ç­”æ¡ˆ:')\n",
    "        print(result['answer'])\n",
    "        \n",
    "        print(f'\\nğŸ“š ç›¸å…³æ¥æº ({len(result[\"sources\"])} ä¸ª):')\n",
    "        for j, source in enumerate(result['sources'][:3], 1):\n",
    "            similarity = source.get('similarity_score', 0)\n",
    "            source_name = source.get('source', 'æœªçŸ¥æ¥æº')\n",
    "            print(f'  {j}. {source_name} (ç›¸ä¼¼åº¦: {similarity:.3f})')\n",
    "        \n",
    "        print(f'\\nâ±ï¸  å¤„ç†æ—¶é—´: {elapsed_time:.2f}ç§’')\n",
    "        \n",
    "        # æ˜¾ç¤ºæ£€ç´¢ç»Ÿè®¡\n",
    "        if 'retrieval_stats' in result:\n",
    "            stats = result['retrieval_stats']\n",
    "            print(f'ğŸ“Š æ£€ç´¢ç»Ÿè®¡:')\n",
    "            print(f'  - ç´¢å¼•æ€»æ–‡æ¡£æ•°: {stats.get(\"total_docs_in_index\", 0)}')\n",
    "            print(f'  - æ£€ç´¢æ–‡æ¡£æ•°: {stats.get(\"docs_retrieved\", 0)}')\n",
    "            print(f'  - æœ€é«˜ç›¸ä¼¼åº¦: {stats.get(\"top_similarity\", 0):.3f}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}')\n",
    "        continue\n",
    "\n",
    "print('\\nâœ… é—®ç­”æµ‹è¯•å®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. äº¤äº’å¼é—®ç­”\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„ä»£ç å—ä¸­è¾“å…¥è‡ªå·±çš„é—®é¢˜è¿›è¡Œæµ‹è¯•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# äº¤äº’å¼é—®ç­”\n",
    "custom_question = \"è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜\"\n",
    "\n",
    "if custom_question and custom_question != \"è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜\":\n",
    "    print(f'ğŸ” å¤„ç†é—®é¢˜: {custom_question}')\n",
    "    \n",
    "    try:\n",
    "        result = rag_pipeline.answer_question(\n",
    "            question=custom_question,\n",
    "            top_k=5,\n",
    "            max_context_length=3000\n",
    "        )\n",
    "        \n",
    "        print(f'\\nğŸ“ ç­”æ¡ˆ:')\n",
    "        print(result['answer'])\n",
    "        \n",
    "        print(f'\\nğŸ“š å‚è€ƒæ¥æº:')\n",
    "        for i, source in enumerate(result['sources'][:5], 1):\n",
    "            similarity = source.get('similarity_score', 0)\n",
    "            source_name = source.get('source', 'æœªçŸ¥æ¥æº')\n",
    "            content_preview = source.get('content', '')[:100] + '...'\n",
    "            print(f'  {i}. {source_name} (ç›¸ä¼¼åº¦: {similarity:.3f})')\n",
    "            print(f'     å†…å®¹é¢„è§ˆ: {content_preview}')\n",
    "            print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}')\n",
    "else:\n",
    "    print('ğŸ’¡ è¯·ä¿®æ”¹ä¸Šé¢çš„ custom_question å˜é‡æ¥æµ‹è¯•æ‚¨è‡ªå·±çš„é—®é¢˜')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ€§èƒ½åˆ†æ\n",
    "\n",
    "åˆ†æRAGç®¡é“çš„æ€§èƒ½è¡¨ç°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "print('=== æ€§èƒ½åˆ†æ ===')\n",
    "\n",
    "# æµ‹è¯•å¤šä¸ªé—®é¢˜çš„å¹³å‡å“åº”æ—¶é—´\n",
    "performance_questions = [\n",
    "    'ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ',\n",
    "    'æ·±åº¦å­¦ä¹ çš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ',\n",
    "    'å¦‚ä½•è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Ÿ',\n",
    "    'ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆï¼Ÿ',\n",
    "    'ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ'\n",
    "]\n",
    "\n",
    "response_times = []\n",
    "similarity_scores = []\n",
    "\n",
    "for question in performance_questions:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = rag_pipeline.answer_question(question, top_k=3)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        response_times.append(elapsed_time)\n",
    "        \n",
    "        # æ”¶é›†ç›¸ä¼¼åº¦åˆ†æ•°\n",
    "        if result['sources']:\n",
    "            top_similarity = result['sources'][0].get('similarity_score', 0)\n",
    "            similarity_scores.append(top_similarity)\n",
    "        \n",
    "        print(f'âœ“ {question[:30]}... - {elapsed_time:.2f}ç§’')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âœ— {question[:30]}... - é”™è¯¯: {e}')\n",
    "\n",
    "# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯\n",
    "if response_times:\n",
    "    avg_time = np.mean(response_times)\n",
    "    min_time = np.min(response_times)\n",
    "    max_time = np.max(response_times)\n",
    "    \n",
    "    print(f'\\nğŸ“Š å“åº”æ—¶é—´ç»Ÿè®¡:')\n",
    "    print(f'  å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ç§’')\n",
    "    print(f'  æœ€å¿«å“åº”æ—¶é—´: {min_time:.2f}ç§’')\n",
    "    print(f'  æœ€æ…¢å“åº”æ—¶é—´: {max_time:.2f}ç§’')\n",
    "\n",
    "if similarity_scores:\n",
    "    avg_similarity = np.mean(similarity_scores)\n",
    "    min_similarity = np.min(similarity_scores)\n",
    "    max_similarity = np.max(similarity_scores)\n",
    "    \n",
    "    print(f'\\nğŸ¯ ç›¸ä¼¼åº¦ç»Ÿè®¡:')\n",
    "    print(f'  å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}')\n",
    "    print(f'  æœ€ä½ç›¸ä¼¼åº¦: {min_similarity:.3f}')\n",
    "    print(f'  æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f}')\n",
    "\n",
    "print('\\nâœ… æ€§èƒ½åˆ†æå®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "æœ¬æ¼”ç¤ºå±•ç¤ºäº†æ— faissä¾èµ–çš„RAGæ£€ç´¢å¢å¼ºç”Ÿæˆç®¡é“çš„å®Œæ•´åŠŸèƒ½ï¼š\n",
    "\n",
    "### âœ… ä¸»è¦åŠŸèƒ½\n",
    "- **å‘é‡æ£€ç´¢**: ä½¿ç”¨numpyå®ç°é«˜æ•ˆçš„å‘é‡ç›¸ä¼¼åº¦è®¡ç®—\n",
    "- **æ–‡æ¡£æ£€ç´¢**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "- **ç­”æ¡ˆç”Ÿæˆ**: ç»“åˆæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ\n",
    "- **æ¥æºè¿½è¸ª**: æä¾›è¯¦ç»†çš„æ¥æºä¿¡æ¯å’Œç›¸ä¼¼åº¦è¯„åˆ†\n",
    "\n",
    "### ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹\n",
    "- **å…¼å®¹æ€§å¥½**: æ— éœ€faissä¾èµ–ï¼Œé€‚ç”¨äºå„ç§ç¯å¢ƒ\n",
    "- **æ€§èƒ½ç¨³å®š**: åŸºäºnumpyçš„å‘é‡è®¡ç®—ï¼Œæ€§èƒ½å¯é \n",
    "- **æ˜“äºéƒ¨ç½²**: ä¾èµ–ç®€å•ï¼Œéƒ¨ç½²æ–¹ä¾¿\n",
    "- **åŠŸèƒ½å®Œæ•´**: æ”¯æŒå®Œæ•´çš„RAGå·¥ä½œæµç¨‹\n",
    "\n",
    "### ğŸ“ˆ åº”ç”¨åœºæ™¯\n",
    "- æ–‡æ¡£é—®ç­”ç³»ç»Ÿ\n",
    "- çŸ¥è¯†åº“æ£€ç´¢\n",
    "- æ™ºèƒ½å®¢æœ\n",
    "- å­¦æœ¯ç ”ç©¶è¾…åŠ©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}